{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOD7UW/lvA0M0nFLg6ZwXRD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g0yPZ7OLh9_g","executionInfo":{"status":"ok","timestamp":1706574113785,"user_tz":480,"elapsed":3742,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"2838603a-8cb2-4ee4-b3c2-03090edd631d"},"outputs":[{"output_type":"stream","name":"stdout","text":["empty(1): tensor([1.6928e+22])\n","empty(3): tensor([-4.5750e-37,  3.3179e-41, -4.5797e-37])\n","empty(2,3): tensor([[-4.5830e-37,  3.3179e-41, -4.5827e-37],\n","        [ 3.3179e-41,  1.1652e-32,  2.5353e+30]])\n","empty(2, 2, 3): tensor([[[-1.9865e-07,  4.5489e-41, -3.9918e-37],\n","         [ 3.3179e-41,  4.4842e-44,  0.0000e+00]],\n","\n","        [[ 1.1210e-43,  0.0000e+00,  1.7912e+03],\n","         [ 3.3172e-41,  1.4013e-45,  0.0000e+00]]])\n","rand(5, 3): tensor([[0.3141, 0.0712, 0.8346],\n","        [0.6552, 0.7213, 0.2897],\n","        [0.3214, 0.7029, 0.6014],\n","        [0.2480, 0.4307, 0.8913],\n","        [0.3695, 0.9863, 0.0286]])\n","zeros(5, 3): tensor([[0., 0., 0.],\n","        [0., 0., 0.],\n","        [0., 0., 0.],\n","        [0., 0., 0.],\n","        [0., 0., 0.]])\n"]}],"source":["import torch\n","\n","# torch.empty(size): unintialized\n","x = torch.empty(1) # scalar\n","print(\"empty(1):\", x)\n","x = torch.empty(3)  #vector\n","print(\"empty(3):\", x)\n","x = torch.empty(2, 3) # matrix\n","print(\"empty(2,3):\", x)\n","x = torch.empty(2, 2, 3)  # tensor, 3 dimensions\n","#x = torch.empty(2, 2, 2, 3) # tensor, 3 dimensions\n","print(\"empty(2, 2, 3):\", x)\n","\n","#torch.rand(size): random numbers [0, 1]\n","x = torch.rand(5, 3)\n","print(\"rand(5, 3):\", x)\n","\n","# torch.zeros(size, fill with 0\n","# torch.ones(size), fill with 1\n","x = torch.zeros(5, 3)\n","print(\"zeros(5, 3):\", x)\n","\n"]},{"cell_type":"code","source":["# check size\n","print(\"size\", x.size()) # x.size(0)\n","print(\"shape\", x.shape) # x.shape[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0je_aTV7mITr","executionInfo":{"status":"ok","timestamp":1706574123235,"user_tz":480,"elapsed":333,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"dd97f2a0-146d-4d83-c06e-da3d0216ddaa"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["size torch.Size([5, 3])\n","shape torch.Size([5, 3])\n"]}]},{"cell_type":"code","source":["# check data type\n","print(x.dtype)\n","\n","#specify types, float32 default\n","x = torch.zeros(5, 3, dtype=torch.float16)\n","print(x)\n","\n","#check type\n","print(x.dtype)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TmXcdRJUmiFk","executionInfo":{"status":"ok","timestamp":1706574132037,"user_tz":480,"elapsed":316,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"888f5e39-bb94-4be1-8e4c-dcdd9eaefc94"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.float32\n","tensor([[0., 0., 0.],\n","        [0., 0., 0.],\n","        [0., 0., 0.],\n","        [0., 0., 0.],\n","        [0., 0., 0.]], dtype=torch.float16)\n","torch.float16\n"]}]},{"cell_type":"code","source":["# construct from data\n","x = torch.tensor([5.5, 3])\n","print(x, x.dtype)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eu323mUtnQsB","executionInfo":{"status":"ok","timestamp":1706574136342,"user_tz":480,"elapsed":341,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"43cae942-fe85-40d2-89a7-b7b71f41aee3"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([5.5000, 3.0000]) torch.float32\n"]}]},{"cell_type":"code","source":["# requires_grad argument\n","# This will tell pytorch that it will need to calculate the gradient for this tensor\n","# later in your optimization steps\n","# i.e. this is a variable in your model that you want to optimize\n","x = torch.tensor([5.5, 3], requires_grad=True)\n","print(x)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ziDLhTHKnkIA","executionInfo":{"status":"ok","timestamp":1706574139057,"user_tz":480,"elapsed":2,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"77ee60d9-c74a-49de-a263-4b4727f772ea"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([5.5000, 3.0000], requires_grad=True)\n"]}]},{"cell_type":"code","source":["# Operations\n","x = torch.ones(2, 2)\n","y = torch.rand(2, 2)\n","\n","#elementwise addition\n","z = x + y\n","# torch.add(x, y)\n","\n","# in place addition, everything with a trailing underscore is an inplace operation\n","# i.e. it will modify the variable\n","# y.add_x(x)\n","\n","print(x)\n","print(y)\n","print(z)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9XCf1PqtsoS3","executionInfo":{"status":"ok","timestamp":1706574142345,"user_tz":480,"elapsed":2,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"03e8662c-d19c-4c96-f9b9-8bf5844f3a69"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 1.],\n","        [1., 1.]])\n","tensor([[0.1559, 0.1493],\n","        [0.4920, 0.5613]])\n","tensor([[1.1559, 1.1493],\n","        [1.4920, 1.5613]])\n"]}]},{"cell_type":"code","source":["# subtraction\n","z = x - y\n","z = torch.sub(x, y)\n","\n","#multiplication\n","z = x * y\n","z = torch.mul(x, y)\n","\n","# division\n","z = x / y\n","z = torch.div(x, y)"],"metadata":{"id":"5Eri-yDWtdPp","executionInfo":{"status":"ok","timestamp":1706574146375,"user_tz":480,"elapsed":310,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Slicing\n","x = torch.rand(5, 3)\n","print(x)\n","print(\"x[:, 0]\", x[:, 0])  # all rows, column 0\n","print(\"x[1, :]\", x[1, :])  # row 1, all columns\n","print(\"x[1, 1]\", x[1, 1])  #  element at 1, 1\n","\n","# Get the actual value if only 1 elment in your tensor\n","print(\"x[1,1].item()\", x[1, 1].item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z-e_B1OVuy3X","executionInfo":{"status":"ok","timestamp":1706574149546,"user_tz":480,"elapsed":329,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"81f62af3-8281-4630-e1ab-072e16c51181"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.1139, 0.6005, 0.6915],\n","        [0.8331, 0.1322, 0.2562],\n","        [0.3927, 0.2311, 0.2957],\n","        [0.8159, 0.1810, 0.4467],\n","        [0.3680, 0.7948, 0.5824]])\n","x[:, 0] tensor([0.1139, 0.8331, 0.3927, 0.8159, 0.3680])\n","x[1, :] tensor([0.8331, 0.1322, 0.2562])\n","x[1, 1] tensor(0.1322)\n","x[1,1].item() 0.1321641206741333\n"]}]},{"cell_type":"code","source":["# Reshape with torch.view()\n","x = torch.randn(4, 4)\n","y = x.view(16)\n","z = x.view(-1, 8) # the size -1 is inferred from other dimensions\n","# if -1 it pytorch will automatically determine the necessary size\n","print(x.size(), y.size(), z.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L5_p9-Atv9v-","executionInfo":{"status":"ok","timestamp":1706574153907,"user_tz":480,"elapsed":535,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"fc7365c0-f8c9-4eb3-a2c5-cdba5d5392bf"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"]}]},{"cell_type":"code","source":["a = torch.ones(5)\n","print(a)\n","\n","# torch to numpy with .numpy()\n","b = a.numpy()\n","print(b)\n","print(type(b))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rwG4FboSwy81","executionInfo":{"status":"ok","timestamp":1706574156917,"user_tz":480,"elapsed":575,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"15a0c04e-e3c2-403e-a0cc-62a40dac6b0a"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1., 1., 1., 1., 1.])\n","[1. 1. 1. 1. 1.]\n","<class 'numpy.ndarray'>\n"]}]},{"cell_type":"code","source":["# Careful:  If the tensor is on the cpu (not the GPU)\n","# both objects will share the same memory location, so changing one\n","# will also change the other\n","a.add_(1)\n","print(a)\n","print(b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zDLG0A70xPG9","executionInfo":{"status":"ok","timestamp":1706574160101,"user_tz":480,"elapsed":517,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"fdb24590-5549-409a-bcfb-a4b32e4c644a"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([2., 2., 2., 2., 2.])\n","[2. 2. 2. 2. 2.]\n"]}]},{"cell_type":"code","source":["# numpy to torch with.from_numpy(x), or torch.tensor() to copy it\n","import numpy as np\n","a = np.ones(5)\n","b = torch.from_numpy(a)\n","c = torch.tensor(a)\n","print(a)\n","print(b)\n","print(c)\n","\n","#again be careful when modifying\n","a += 1\n","print(a)\n","print(b)\n","print(c)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3tIobIWS_mYV","executionInfo":{"status":"ok","timestamp":1706574163626,"user_tz":480,"elapsed":4,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"5b67be2b-a2f3-44df-80e7-c40741fff55f"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["[1. 1. 1. 1. 1.]\n","tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n","tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n","[2. 2. 2. 2. 2.]\n","tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n","tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"]}]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","#x = x.to(\"cpu\")\n","#x = x.to(\"cuda\")\n","\n","x = torch.rand(2,2, device=device)  # or directly create them on GPU\n"],"metadata":{"id":"LOx_dBvJBOXC","executionInfo":{"status":"ok","timestamp":1706574167861,"user_tz":480,"elapsed":477,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","# requires_grad = True -> tracks all operations on he tensor.\n","x = torch.randn(3, requires_grad=True)\n","y = x + 2\n","\n","# y was created as result of an operation, so it has a ggrad_fn attribute\n","# grad_fn: reference a Function that has created the Tensor\n","print(x)  # created by the user -> grad_fn is None\n","print(y)\n","print(y.grad_fn)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XY2iayOAElsr","executionInfo":{"status":"ok","timestamp":1706603449509,"user_tz":480,"elapsed":6926,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"fe41f15b-54a4-4586-c2c3-42b05c04e6ac"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 0.3894, -0.2876, -0.2883], requires_grad=True)\n","tensor([2.3894, 1.7124, 1.7117], grad_fn=<AddBackward0>)\n","<AddBackward0 object at 0x7c7f9565cdc0>\n"]}]},{"cell_type":"code","source":["# Do more operations on y\n","z = y * y * 3\n","print(z)\n","z = z.mean()\n","print(z)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bAO5v79yHu3R","executionInfo":{"status":"ok","timestamp":1706603449510,"user_tz":480,"elapsed":5,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"6bedc0c5-6896-479c-c458-bcbce94e97b5"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([17.1278,  8.7971,  8.7897], grad_fn=<MulBackward0>)\n","tensor(11.5715, grad_fn=<MeanBackward0>)\n"]}]},{"cell_type":"code","source":["# Let's compute the gradients with backpropagation\n","# When we finish our computation we can call .backward() and have all the gradients computed automatically.\n","# The gradient for this tensor will be accumlated into .grad attribute.\n","# It is the partial derivate of the function w.r.t. the tensor\n","\n","print(x.grad)\n","z.backward()\n","print(x.grad) # dz/dx\n","\n","# !!! Careful!!! backward() accumulates the gradient for this tensor into .grad attribute.\n","# !!! We need to be careful during optimzation !!! optimizer.zero_grad()"],"metadata":{"id":"-C8E9VOJIdrY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706603454021,"user_tz":480,"elapsed":197,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"3620bd79-e009-4687-d00c-5b9bdf7d632e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["None\n","tensor([4.7788, 3.4248, 3.4234])\n"]}]},{"cell_type":"markdown","source":["Stop a tensor from tracking history:\n","\n","For example during the training loop when we want to updte our weights, or after trainingg during evaluation.  These operations should not be part of the gradient computation.  To prevent this, wecan use:\n","x.reuires_grad_(False)\n","x.detach()\n","wrap in with torch.no_grad();"],"metadata":{"id":"e5H0qdDJ6G5W"}},{"cell_type":"code","source":["# .requires_grad_(...). changes an existing flag in-place.\n","a = torch.randn(2, 2)\n","b = (a * a).sum()\n","print(a.requires_grad)\n","print(b.grad_fn)\n","\n","a.requires_grad_(True)\n","b = (a * a).sum()\n","print(a.requires_grad)\n","print(b.grad_fn)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HKgMfB896vXu","executionInfo":{"status":"ok","timestamp":1706603458953,"user_tz":480,"elapsed":302,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"8ddbf794-23bb-4cb5-916f-05d38e020979"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["False\n","None\n","True\n","<SumBackward0 object at 0x7c7f9565d7b0>\n"]}]},{"cell_type":"code","source":["# .detach():  get a new Tensor with the same content but no gradient computation:\n","a = torch.randn(2, 2, requires_grad=True)\n","b = a.detach()\n","print(a.requires_grad)\n","print(b.requires_grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4MJXufQW7k7R","executionInfo":{"status":"ok","timestamp":1706603462853,"user_tz":480,"elapsed":160,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"6bd10e81-73cc-4fa7-e9b3-7eba246bea57"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","False\n"]}]},{"cell_type":"code","source":["# wrap in 'with torch.no_grad():'\n","a = torch.randn(2, 2, requires_grad=True)\n","print(a.requires_grad)\n","with torch.no_grad():\n","  b = a ** 2\n","  print(b.requires_grad)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aNSxpAqIR0Qj","executionInfo":{"status":"ok","timestamp":1706603465255,"user_tz":480,"elapsed":153,"user":{"displayName":"Tzechung Kao","userId":"14252687860553419910"}},"outputId":"6211e993-d9c8-4a3a-bf10-abe29a86c8cd"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","False\n"]}]}]}